dataset:
  train_file: ../my_datasets/learning-agency-lab-automated-essay-scoring-2/train.csv
  fold_file: ../my_datasets/folds/folds4.csv
  external: null
  n_samples_in_train: 12981
  remove_pc2_in_train: true
  sampling:
    enable: false
    method: by_dist
model:
  save_path: ../models/exp302_cope_aes2-deberta-v3-large-10
  path: /root/autodl-tmp/aes2-deberta-v3-large-10
  head: ''
  pooling: attention
  layer_start: 12
  msd: false
  num_reinit_layers: 0
  differential_lr:
    enable: true
    lr_factor: 2.6
  llrd:
    enable: false
    value: 0.9
  n_labels: 1
  task_type: regression
optim:
  optimizer:
    name: adamw8bit
    lookahead: false
    lr: 1.0e-05
    head_lr: 1.0e-05
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-06
    weight_decay: 0.01
  scheduler:
    name: linear
    warmup_percent: 0.0
    num_warmup_steps: 0
    kwargs: {}
train:
  fold: 3
  stage: 2
  exp_name: exp302_cope
  device: cuda
  num_folds: 4
  fullfit: false
  seed: 515
  use_random_seed: false
  ensure_data_order: false
  reinit_weights: true
  loss: mse
  loss_factor: -1
  accumulate_grad: 1
  max_length: 1024
  validate_max_length: 1024
  batch_size: 16
  log_steps: 25
  epochs: 3
  num_workers: 4
  max_grad_norm: 10
  validation_interval: 1
  precision: bf16
  gradient_checkpointing: true
  freeze_embeddings: false
  freeze_encoders: 0
  save_last_checkpoint: true
  use_wandb: true
  use_cope: true
awp:
  tag: not implement yet
  enable: false
  from_score: 0.48
  adv_param: weight
  adv_lr: 1
  adv_eps: 0.01
  start_epoch: 1
  adv_step: 1
ema:
  tag: not implement yet
  enable: false
  from_score: 100
  decay: 0.999
mixout:
  enable: false
  p: 0.1
multi_task:
  enable: false
  weight: 0.8
  tasks:
  - readability
  path: ???
pl:
  enable: false
  path: ../my_datasets/pl/exp302d_large/PL_exp302d_large_last_fold{fold}.csv
  stage: 1
  prev_model_path: ???
